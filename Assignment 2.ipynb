{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB CHALLENGE: Neural Matrix Factorization \n",
    "In the previous lecture we have built a recommender system using the Neural Matrix Factorization framework. This framework allowed us to combine the GMF layers with the MLP layers in this way:\n",
    "$$\\phi^{GMF} = \\mathbf{p_u}^G\\odot \\mathbf{q_i}^G$$\n",
    "$$\\phi^{MLP} = a_L(\\mathbf{W}_L^T(a_{L-1}(...a_2 (\\mathbf{W}_2^T \\begin{bmatrix}\n",
    "\\mathbf{p_u} \\\\ \\mathbf{q_i}\n",
    "\\end{bmatrix} + \\mathbf{b}_2)...)) + \\mathbf{b}_L)$$\n",
    "\n",
    "$$ y_{ui} = \\sigma(\\mathbf{h}^T \\begin{bmatrix}\n",
    "\\ \\phi^{GMF} \\\\ \\phi^{MLP}\n",
    "\\end{bmatrix})$$\n",
    "\n",
    "<center>  <img src=\"https://drive.google.com/uc?export=view&id=1gNLUpiQdbDPMdvfZYVs3lcou3cd4Favb\" width=\"550\" height=\"400\"> </center> \n",
    "\n",
    "Let's now try to apply transfer learning to such an architecture. \n",
    "\n",
    "- TASK 1: Train the GMF and MLP models separately, inspect and save the parameters.\n",
    "- TASK 2: Use the pre-trained parameters for initializing the NMF architecture. In particular, use the pre-trained embeddings for users and items and the initialized layers of GMF and MLP.\n",
    "- TASK 3: Finally, train the NMF model both by freezing the layers preceding the NeuMF layer and by keeping all the parameters trainable. Compare the performance with the network trained from scratch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agoniko/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#from ray import tune\n",
    "#from ray.tune import CLIReporter\n",
    "#from ray.tune.schedulers import ASHAScheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "from neumf import NeuMF\n",
    "from metrics import metrics\n",
    "from NCF_Data import NCF_Data\n",
    "from dl import data_loaders_from_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATH definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./ml-100k/u.data\" \n",
    "MODEL_PATH = \"./models/\" "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"seed\": 42,\n",
    "    \"lr\": 0.001,\n",
    "    \"dropout\": 0.0,\n",
    "    \"batch_size\": 256,\n",
    "    \"epochs\": 30,\n",
    "    \"top_k\": 10,\n",
    "    \"num_factors\": 8,\n",
    "    \"layers\": (64, 32, 16, 8),\n",
    "    \"out\": True,\n",
    "    \"num_ng\": 4,\n",
    "    \"num_ng_test\": 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = {\n",
    "    \"lr\": 0.01,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_factors_gmf\": 16,\n",
    "    \"num_factors_mlp\": 64,\n",
    "    \"epochs\": 30,\n",
    "    \"out\": True,\n",
    "    \"dropout\": [0, 0, 0, 0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(args[\"seed\"])\n",
    "torch.manual_seed(args[\"seed\"])\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train and Test loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "ml_100k = pd.read_csv(\n",
    "\tPATH, \n",
    "\tsep=\"\\t\", \n",
    "\tnames = ['user_id', 'item_id', 'rating', 'timestamp'], \n",
    "\tengine='python')\n",
    "\n",
    "# set the num_users, items\n",
    "num_users = ml_100k['user_id'].nunique()+1\n",
    "num_items = ml_100k['item_id'].nunique()+1\n",
    "\n",
    "# construct the train and test datasets\n",
    "data = NCF_Data(ml_100k, args)\n",
    "train_loader = data.get_train_instance()\n",
    "test_loader = data.get_test_instance()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module, train_loader: DataLoader, test_loader: DataLoader, optimizer = None, name_suffix = \"\"):\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    loss_function = nn.BCELoss()\n",
    "    if optimizer == None:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args[\"lr\"])\n",
    "\n",
    "    best_hr = 0\n",
    "    \n",
    "    # Train cycle\n",
    "    for epoch in range(args[\"epochs\"]):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Train step\n",
    "        model.train()\n",
    "\n",
    "        for user, item, label in train_loader:\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            # Zero grad\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Prediction\n",
    "            prediction = model(user, item)\n",
    "            loss = loss_function(prediction, label)\n",
    "            \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Eval metrics\n",
    "        model.eval()\n",
    "        HR, NDCG = metrics(model, test_loader, args[\"top_k\"], device)\n",
    "\n",
    "        # Print metrics and time elapsed\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\n",
    "            \"Epoch {:03d}\".format(epoch)\n",
    "            + \" time to train: \"\n",
    "            + time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time))\n",
    "        )\n",
    "        print(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG)))\n",
    "\n",
    "        # If best model, save it\n",
    "        if HR > best_hr:\n",
    "            best_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n",
    "            if args[\"out\"]:\n",
    "                if not os.path.exists(MODEL_PATH):\n",
    "                    os.mkdir(MODEL_PATH)\n",
    "                torch.save(\n",
    "                    model, \"{}{}{}{}.pt\".format(MODEL_PATH, model.__class__.__name__, model.num_factors, name_suffix)\n",
    "                )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items):\n",
    "        super(GMF, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_factors = args[\"num_factors\"]\n",
    "\n",
    "        self.embedding_user = nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.num_factors\n",
    "        )\n",
    "        self.embedding_item = nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.num_factors\n",
    "        )\n",
    "\n",
    "        self.affine_output = nn.Linear(in_features=self.num_factors, out_features=1)\n",
    "        self.logistic = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding = self.embedding_user(user_indices)\n",
    "        item_embedding = self.embedding_item(item_indices)\n",
    "        element_product = torch.mul(user_embedding, item_embedding)\n",
    "        logits = self.affine_output(element_product)\n",
    "        rating = self.logistic(logits)\n",
    "        return rating.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 time to train: 00: 00: 08\n",
      "HR: 0.104\tNDCG: 0.043\n",
      "Epoch 001 time to train: 00: 00: 08\n",
      "HR: 0.076\tNDCG: 0.036\n",
      "Epoch 002 time to train: 00: 00: 09\n",
      "HR: 0.112\tNDCG: 0.051\n",
      "Epoch 003 time to train: 00: 00: 12\n",
      "HR: 0.129\tNDCG: 0.063\n",
      "Epoch 004 time to train: 00: 00: 11\n",
      "HR: 0.209\tNDCG: 0.102\n",
      "Epoch 005 time to train: 00: 00: 13\n",
      "HR: 0.277\tNDCG: 0.146\n",
      "Epoch 006 time to train: 00: 00: 12\n",
      "HR: 0.320\tNDCG: 0.173\n",
      "Epoch 007 time to train: 00: 00: 12\n",
      "HR: 0.352\tNDCG: 0.190\n",
      "Epoch 008 time to train: 00: 00: 11\n",
      "HR: 0.388\tNDCG: 0.208\n",
      "Epoch 009 time to train: 00: 00: 12\n",
      "HR: 0.399\tNDCG: 0.223\n",
      "Epoch 010 time to train: 00: 00: 12\n",
      "HR: 0.435\tNDCG: 0.240\n",
      "Epoch 011 time to train: 00: 00: 10\n",
      "HR: 0.469\tNDCG: 0.260\n",
      "Epoch 012 time to train: 00: 00: 10\n",
      "HR: 0.483\tNDCG: 0.268\n",
      "Epoch 013 time to train: 00: 00: 10\n",
      "HR: 0.501\tNDCG: 0.280\n",
      "Epoch 014 time to train: 00: 00: 10\n",
      "HR: 0.517\tNDCG: 0.289\n",
      "Epoch 015 time to train: 00: 00: 10\n",
      "HR: 0.538\tNDCG: 0.298\n",
      "Epoch 016 time to train: 00: 00: 11\n",
      "HR: 0.550\tNDCG: 0.303\n",
      "Epoch 017 time to train: 00: 00: 10\n",
      "HR: 0.551\tNDCG: 0.307\n",
      "Epoch 018 time to train: 00: 00: 11\n",
      "HR: 0.560\tNDCG: 0.310\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m gmf_model \u001b[39m=\u001b[39m GMF(num_users, num_items)\n\u001b[0;32m----> 2\u001b[0m train_model(gmf_model, train_loader, test_loader)\n\u001b[1;32m      3\u001b[0m \u001b[39m#gmf_model = torch.load(MODEL_PATH + \"GMF8.pt\", map_location=device)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, optimizer, name_suffix)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m# Train step\u001b[39;00m\n\u001b[1;32m     16\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfor\u001b[39;00m user, item, label \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m     19\u001b[0m     user \u001b[39m=\u001b[39m user\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m     item \u001b[39m=\u001b[39m item\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 624\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profile_name):\n\u001b[1;32m    625\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m             \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/autograd/profiler.py:493\u001b[0m, in \u001b[0;36mrecord_function.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type: Any, exc_value: Any, traceback: Any):\n\u001b[1;32m    492\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_callbacks_on_exit:\n\u001b[0;32m--> 493\u001b[0m         torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49m_record_function_exit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle)\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/_ops.py:442\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    438\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    440\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    441\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gmf_model = GMF(num_users, num_items)\n",
    "train_model(gmf_model, train_loader, test_loader)\n",
    "#gmf_model = torch.load(MODEL_PATH + \"GMF8.pt\", map_location=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_users, num_items):\n",
    "        super(MLP, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_factors = args[\"num_factors\"]\n",
    "\n",
    "        self.embedding_user = nn.Embedding(\n",
    "            num_embeddings=num_users, embedding_dim=args[\"num_factors\"]\n",
    "        )\n",
    "        self.embedding_item = nn.Embedding(\n",
    "            num_embeddings=num_items, embedding_dim=args[\"num_factors\"]\n",
    "        )\n",
    "\n",
    "        layer_sizes = args[\"layers\"]\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(args[\"num_factors\"] * 2, layer_sizes[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "        for in_size, out_size in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            layers.append(nn.Linear(in_size, out_size))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.mlp_fc = nn.Sequential(*layers)\n",
    "        self.mlp_fc.add_module(\"affine\", nn.Linear(layer_sizes[-1], 1))\n",
    "        self.mlp_fc.add_module(\"logit\", nn.Sigmoid())\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding = self.embedding_user(user_indices)\n",
    "        item_embedding = self.embedding_item(item_indices)\n",
    "        vector = torch.cat([user_embedding, item_embedding], dim=-1)\n",
    "        rating = self.mlp_fc(vector)\n",
    "        return rating.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 time to train: 00: 00: 15\n",
      "HR: 0.408\tNDCG: 0.213\n",
      "Epoch 001 time to train: 00: 00: 16\n",
      "HR: 0.496\tNDCG: 0.280\n",
      "Epoch 002 time to train: 00: 00: 16\n",
      "HR: 0.530\tNDCG: 0.303\n",
      "Epoch 003 time to train: 00: 00: 16\n",
      "HR: 0.565\tNDCG: 0.320\n",
      "Epoch 004 time to train: 00: 00: 16\n",
      "HR: 0.575\tNDCG: 0.327\n",
      "Epoch 005 time to train: 00: 00: 16\n",
      "HR: 0.574\tNDCG: 0.327\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m args[\u001b[39m'\u001b[39m\u001b[39mlayers\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [\u001b[39m64\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m]\n\u001b[1;32m      5\u001b[0m mlp_model \u001b[39m=\u001b[39m MLP(num_users, num_items)\n\u001b[0;32m----> 6\u001b[0m train_model(mlp_model, train_loader, test_loader)\n\u001b[1;32m      7\u001b[0m \u001b[39m#mlp_model = torch.load(MODEL_PATH + \"MLP64.pt\", map_location=device)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, optimizer, name_suffix)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[39m# Backpropagation\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 32\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     34\u001b[0m \u001b[39m# Eval metrics\u001b[39;00m\n\u001b[1;32m     35\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    235\u001b[0m          grads,\n\u001b[1;32m    236\u001b[0m          exp_avgs,\n\u001b[1;32m    237\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    238\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    239\u001b[0m          state_steps,\n\u001b[1;32m    240\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    241\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    242\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    243\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    244\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    245\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    246\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    247\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    248\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    249\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    250\u001b[0m          fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    251\u001b[0m          grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    252\u001b[0m          found_inf\u001b[39m=\u001b[39;49mfound_inf)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m func(params,\n\u001b[1;32m    301\u001b[0m      grads,\n\u001b[1;32m    302\u001b[0m      exp_avgs,\n\u001b[1;32m    303\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    304\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    305\u001b[0m      state_steps,\n\u001b[1;32m    306\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    307\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    308\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    309\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    310\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    311\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    312\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    313\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    314\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    315\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    316\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/optim/adam.py:410\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    408\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m bias_correction2_sqrt)\u001b[39m.\u001b[39;49madd_(eps)\n\u001b[1;32m    412\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args[\"lr\"] = 0.01\n",
    "args[\"dropout\"] = 0\n",
    "args[\"num_factors\"] = 64\n",
    "args['layers'] = [64, 32, 16, 8]\n",
    "mlp_model = MLP(num_users, num_items)\n",
    "train_model(mlp_model, train_loader, test_loader)\n",
    "#mlp_model = torch.load(MODEL_PATH + \"MLP64.pt\", map_location=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 time to train: 00: 00: 19\n",
      "HR: 0.402\tNDCG: 0.232\n",
      "Epoch 001 time to train: 00: 00: 20\n",
      "HR: 0.528\tNDCG: 0.307\n",
      "Epoch 002 time to train: 00: 00: 19\n",
      "HR: 0.578\tNDCG: 0.330\n",
      "Epoch 003 time to train: 00: 00: 19\n",
      "HR: 0.597\tNDCG: 0.346\n",
      "Epoch 004 time to train: 00: 00: 19\n",
      "HR: 0.601\tNDCG: 0.351\n",
      "Epoch 005 time to train: 00: 00: 19\n",
      "HR: 0.626\tNDCG: 0.371\n",
      "Epoch 006 time to train: 00: 00: 19\n",
      "HR: 0.620\tNDCG: 0.350\n",
      "Epoch 007 time to train: 00: 00: 19\n",
      "HR: 0.617\tNDCG: 0.363\n",
      "Epoch 008 time to train: 00: 00: 19\n",
      "HR: 0.619\tNDCG: 0.369\n",
      "Epoch 009 time to train: 00: 00: 19\n",
      "HR: 0.630\tNDCG: 0.376\n",
      "Epoch 010 time to train: 00: 00: 19\n",
      "HR: 0.630\tNDCG: 0.379\n",
      "Epoch 011 time to train: 00: 00: 19\n",
      "HR: 0.627\tNDCG: 0.365\n",
      "Epoch 012 time to train: 00: 00: 19\n",
      "HR: 0.633\tNDCG: 0.365\n",
      "Epoch 013 time to train: 00: 00: 19\n",
      "HR: 0.635\tNDCG: 0.381\n",
      "Epoch 014 time to train: 00: 00: 19\n",
      "HR: 0.630\tNDCG: 0.375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#nmf_model = torch.load(MODEL_PATH + \"Assignment 1 - best.pt\", map_location=device)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m nmf_model \u001b[39m=\u001b[39m NeuMF(gmf_model\u001b[39m.\u001b[39mnum_factors, mlp_model\u001b[39m.\u001b[39mnum_factors, num_users, num_items)\n\u001b[0;32m----> 3\u001b[0m train_model(nmf_model, train_loader, test_loader)\n",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, optimizer, name_suffix)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[39m# Backpropagation\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 32\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     34\u001b[0m \u001b[39m# Eval metrics\u001b[39;00m\n\u001b[1;32m     35\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    235\u001b[0m          grads,\n\u001b[1;32m    236\u001b[0m          exp_avgs,\n\u001b[1;32m    237\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    238\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    239\u001b[0m          state_steps,\n\u001b[1;32m    240\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    241\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    242\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    243\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    244\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    245\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    246\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    247\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    248\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    249\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    250\u001b[0m          fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    251\u001b[0m          grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    252\u001b[0m          found_inf\u001b[39m=\u001b[39;49mfound_inf)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m func(params,\n\u001b[1;32m    301\u001b[0m      grads,\n\u001b[1;32m    302\u001b[0m      exp_avgs,\n\u001b[1;32m    303\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    304\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    305\u001b[0m      state_steps,\n\u001b[1;32m    306\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    307\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    308\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    309\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    310\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    311\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    312\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    313\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    314\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    315\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    316\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/optim/adam.py:412\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m--> 412\u001b[0m param\u001b[39m.\u001b[39;49maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#nmf_model = torch.load(MODEL_PATH + \"Assignment 1 - best.pt\", map_location=device)\n",
    "nmf_model = NeuMF(gmf_model.num_factors, mlp_model.num_factors, num_users, num_items)\n",
    "train_model(nmf_model, train_loader, test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining functions that load sub_models weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gmf_weights(nmf_model, gmf_model, requires_grad=False):\n",
    "    nmf_layers_names = [name for name, param in nmf_model.named_parameters()]\n",
    "    gmf_layers_names = [name for name, param in gmf_model.named_parameters()]\n",
    "    #create a dict that has as key the value of the layer in the NMF model and as value the layer in the GMF model\n",
    "    layers_name_match_dict = {k: v for k, v in zip(nmf_layers_names[:2], gmf_layers_names)}\n",
    "    for nmf_layer_name, gmf_layer_name in layers_name_match_dict.items():\n",
    "        nmf_model.state_dict()[nmf_layer_name].copy_(gmf_model.state_dict()[gmf_layer_name])\n",
    "    #deactivate grad for the layers that comes from the GMF model\n",
    "    for name, param in nmf_model.named_parameters():\n",
    "        if name in layers_name_match_dict.keys():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "\n",
    "def load_mlp_weights(nmf_model, mlp_model, requires_grad=False):\n",
    "    nmf_layers_names = [name for name, param in nmf_model.named_parameters()]\n",
    "    mlp_layers_names = [name for name, param in mlp_model.named_parameters()]\n",
    "    #create a dict that has as key the value of the layer in the NMF model and as value the layer in the MLP model\n",
    "    layers_name_match_dict = {k: v for k, v in zip(nmf_layers_names[4:], mlp_layers_names[:-2])}\n",
    "    for nmf_layer_name, mlp_layer_name in layers_name_match_dict.items():\n",
    "        nmf_model.state_dict()[nmf_layer_name].copy_(mlp_model.state_dict()[mlp_layer_name])\n",
    "    #deactivate grad for the layers that comes from the MLP model\n",
    "    for name, param in nmf_model.named_parameters():\n",
    "        if name in layers_name_match_dict.keys():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "\n",
    "def load_pre_trained_weights(nmf_model, gmf_model, mlp_model, requires_grad = False):\n",
    "    load_gmf_weights(nmf_model, gmf_model, requires_grad)\n",
    "    load_mlp_weights(nmf_model, mlp_model, requires_grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance with sum_models layers freezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NeuMF(gmf_model.num_factors, mlp_model.num_factors, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.8607, -0.6964,  0.1080,  ..., -0.3891, -0.3114,  0.2891],\n",
       "        [-1.7776, -0.7549, -0.5014,  ..., -0.8672, -1.2736,  1.8885],\n",
       "        [-1.0263, -0.3188,  0.1639,  ..., -1.4060,  0.4446,  1.7400],\n",
       "        ...,\n",
       "        [-1.0257, -0.1594,  2.5053,  ...,  0.8206, -0.7009, -0.3864],\n",
       "        [ 0.6466,  1.1461, -0.9856,  ...,  1.2255,  0.4219,  1.0278],\n",
       "        [ 0.7051,  0.0172,  0.4435,  ..., -0.6819,  1.3587,  0.5732]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nmf_model.named_parameters())[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pre_trained_weights(nmf_model, gmf_model, mlp_model, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3085,  0.8726, -1.1722,  ...,  0.0699, -1.9647,  0.1729],\n",
       "        [-1.4784, -0.3342, -0.7074,  ...,  0.6181,  0.7528, -1.3338],\n",
       "        [-0.6959, -0.8064,  0.5510,  ..., -0.8175, -0.7989, -0.9837],\n",
       "        ...,\n",
       "        [-0.5350,  2.0469, -0.3441,  ...,  1.9913,  0.7408, -0.9911],\n",
       "        [ 0.8546,  1.2619,  0.4588,  ...,  0.9866,  0.0935, -1.0636],\n",
       "        [ 2.3216,  1.0117,  1.2533,  ...,  1.2931,  1.1044,  2.8907]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nmf_model.named_parameters())[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmf_user_embed.0.weight False\n",
      "gmf_item_embed.0.weight False\n",
      "gmf_affine.weight True\n",
      "gmf_affine.bias True\n",
      "mlp_user_embed.0.weight False\n",
      "mlp_item_embed.0.weight False\n",
      "mlp_fc.0.weight False\n",
      "mlp_fc.0.bias False\n",
      "mlp_fc.3.weight False\n",
      "mlp_fc.3.bias False\n",
      "mlp_fc.6.weight False\n",
      "mlp_fc.6.bias False\n",
      "mlp_fc.9.weight False\n",
      "mlp_fc.9.bias False\n",
      "mixing_layers.0.weight True\n",
      "mixing_layers.0.bias True\n",
      "mixing_layers.3.weight True\n",
      "mixing_layers.3.bias True\n",
      "mixing_layers.6.weight True\n",
      "mixing_layers.6.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in nmf_model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 time to train: 00: 00: 10\n",
      "HR: 0.597\tNDCG: 0.338\n",
      "Epoch 001 time to train: 00: 00: 10\n",
      "HR: 0.595\tNDCG: 0.336\n",
      "Epoch 002 time to train: 00: 00: 13\n",
      "HR: 0.599\tNDCG: 0.337\n",
      "Epoch 003 time to train: 00: 00: 13\n",
      "HR: 0.593\tNDCG: 0.339\n",
      "Epoch 004 time to train: 00: 00: 13\n",
      "HR: 0.598\tNDCG: 0.337\n",
      "Epoch 005 time to train: 00: 00: 13\n",
      "HR: 0.600\tNDCG: 0.336\n",
      "Epoch 006 time to train: 00: 00: 13\n",
      "HR: 0.596\tNDCG: 0.334\n",
      "Epoch 007 time to train: 00: 00: 13\n",
      "HR: 0.601\tNDCG: 0.338\n",
      "Epoch 008 time to train: 00: 00: 13\n",
      "HR: 0.593\tNDCG: 0.338\n",
      "Epoch 009 time to train: 00: 00: 15\n",
      "HR: 0.597\tNDCG: 0.336\n",
      "Epoch 010 time to train: 00: 00: 13\n",
      "HR: 0.597\tNDCG: 0.339\n",
      "Epoch 011 time to train: 00: 00: 13\n",
      "HR: 0.600\tNDCG: 0.337\n",
      "Epoch 012 time to train: 00: 00: 13\n",
      "HR: 0.592\tNDCG: 0.336\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_model(nmf_model, train_loader, test_loader, name_suffix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m-freezed42\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[11], line 27\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, optimizer, name_suffix)\u001b[0m\n\u001b[1;32m     24\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     26\u001b[0m \u001b[39m# Prediction\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m prediction \u001b[39m=\u001b[39m model(user, item)\n\u001b[1;32m     28\u001b[0m loss \u001b[39m=\u001b[39m loss_function(prediction, label)\n\u001b[1;32m     30\u001b[0m \u001b[39m# Backpropagation\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/neumf.py:84\u001b[0m, in \u001b[0;36mNeuMF.forward\u001b[0;34m(self, user_indices, item_indices)\u001b[0m\n\u001b[1;32m     81\u001b[0m user_embedding_mlp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_user_embed(user_indices)\n\u001b[1;32m     82\u001b[0m item_embedding_mlp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_item_embed(item_indices)\n\u001b[0;32m---> 84\u001b[0m vector \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat((user_embedding_mlp, item_embedding_mlp), dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     85\u001b[0m ratings_mlp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_fc(vector)\n\u001b[1;32m     87\u001b[0m ratings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((ratings_gmf, ratings_mlp), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(nmf_model, train_loader, test_loader, name_suffix=\"-freezed42\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance letting initialized layers free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmf_user_embed.0.weight True\n",
      "gmf_item_embed.0.weight True\n",
      "gmf_affine.weight True\n",
      "gmf_affine.bias True\n",
      "mlp_user_embed.0.weight True\n",
      "mlp_item_embed.0.weight True\n",
      "mlp_fc.0.weight True\n",
      "mlp_fc.0.bias True\n",
      "mlp_fc.3.weight True\n",
      "mlp_fc.3.bias True\n",
      "mlp_fc.6.weight True\n",
      "mlp_fc.6.bias True\n",
      "mlp_fc.9.weight True\n",
      "mlp_fc.9.bias True\n",
      "mixing_layers.0.weight True\n",
      "mixing_layers.0.bias True\n",
      "mixing_layers.3.weight True\n",
      "mixing_layers.3.bias True\n",
      "mixing_layers.6.weight True\n",
      "mixing_layers.6.bias True\n"
     ]
    }
   ],
   "source": [
    "nmf_model = NeuMF(gmf_model.num_factors, mlp_model.num_factors, num_users, num_items)\n",
    "#nmf_model = torch.load(MODEL_PATH + \"NeuMF64-freezed.pt\", map_location=device)\n",
    "load_pre_trained_weights(nmf_model, gmf_model, mlp_model, requires_grad=True)\n",
    "for name, param in nmf_model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 time to train: 00: 00: 18\n",
      "HR: 0.615\tNDCG: 0.346\n",
      "Epoch 001 time to train: 00: 00: 20\n",
      "HR: 0.620\tNDCG: 0.360\n",
      "Epoch 002 time to train: 00: 00: 20\n",
      "HR: 0.637\tNDCG: 0.357\n",
      "Epoch 003 time to train: 00: 00: 20\n",
      "HR: 0.646\tNDCG: 0.365\n",
      "Epoch 004 time to train: 00: 00: 19\n",
      "HR: 0.637\tNDCG: 0.359\n",
      "Epoch 005 time to train: 00: 00: 19\n",
      "HR: 0.644\tNDCG: 0.368\n",
      "Epoch 006 time to train: 00: 00: 19\n",
      "HR: 0.648\tNDCG: 0.371\n",
      "Epoch 007 time to train: 00: 00: 19\n",
      "HR: 0.637\tNDCG: 0.369\n",
      "Epoch 008 time to train: 00: 00: 19\n",
      "HR: 0.642\tNDCG: 0.373\n",
      "Epoch 009 time to train: 00: 00: 19\n",
      "HR: 0.628\tNDCG: 0.365\n",
      "Epoch 010 time to train: 00: 00: 19\n",
      "HR: 0.622\tNDCG: 0.369\n",
      "Epoch 011 time to train: 00: 00: 19\n",
      "HR: 0.629\tNDCG: 0.366\n",
      "Epoch 012 time to train: 00: 00: 19\n",
      "HR: 0.600\tNDCG: 0.365\n",
      "Epoch 013 time to train: 00: 00: 19\n",
      "HR: 0.618\tNDCG: 0.361\n",
      "Epoch 014 time to train: 00: 00: 19\n",
      "HR: 0.620\tNDCG: 0.360\n",
      "Epoch 015 time to train: 00: 00: 19\n",
      "HR: 0.614\tNDCG: 0.362\n",
      "Epoch 016 time to train: 00: 00: 19\n",
      "HR: 0.622\tNDCG: 0.358\n",
      "Epoch 017 time to train: 00: 00: 19\n",
      "HR: 0.618\tNDCG: 0.361\n",
      "Epoch 018 time to train: 00: 00: 45\n",
      "HR: 0.638\tNDCG: 0.366\n",
      "Epoch 019 time to train: 00: 00: 59\n",
      "HR: 0.632\tNDCG: 0.366\n",
      "Epoch 020 time to train: 00: 00: 58\n",
      "HR: 0.624\tNDCG: 0.363\n",
      "Epoch 021 time to train: 00: 00: 58\n",
      "HR: 0.615\tNDCG: 0.350\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_model(nmf_model, train_loader, test_loader, name_suffix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m-free\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, optimizer, name_suffix)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[39m# Backpropagation\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 32\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     34\u001b[0m \u001b[39m# Eval metrics\u001b[39;00m\n\u001b[1;32m     35\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    235\u001b[0m          grads,\n\u001b[1;32m    236\u001b[0m          exp_avgs,\n\u001b[1;32m    237\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    238\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    239\u001b[0m          state_steps,\n\u001b[1;32m    240\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    241\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    242\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    243\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    244\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    245\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    246\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    247\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    248\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    249\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    250\u001b[0m          fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    251\u001b[0m          grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    252\u001b[0m          found_inf\u001b[39m=\u001b[39;49mfound_inf)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m func(params,\n\u001b[1;32m    301\u001b[0m      grads,\n\u001b[1;32m    302\u001b[0m      exp_avgs,\n\u001b[1;32m    303\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    304\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    305\u001b[0m      state_steps,\n\u001b[1;32m    306\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    307\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    308\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    309\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    310\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    311\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    312\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    313\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    314\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    315\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    316\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/Desktop/Uni/DEEP_LEARNING/Transfer Learning/.venv/lib/python3.10/site-packages/torch/optim/adam.py:353\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[39m# update step\u001b[39;00m\n\u001b[1;32m    351\u001b[0m step_t \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 353\u001b[0m \u001b[39mif\u001b[39;00m weight_decay \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    354\u001b[0m     grad \u001b[39m=\u001b[39m grad\u001b[39m.\u001b[39madd(param, alpha\u001b[39m=\u001b[39mweight_decay)\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_complex(param):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(nmf_model, train_loader, test_loader, name_suffix=\"-free\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_freezed = torch.load(MODEL_PATH + \"NeuMF64-freezed.pt\", map_location = device)\n",
    "gmf_best = torch.load(MODEL_PATH + \"GMF8.pt\", map_location = device)\n",
    "mlp_best = torch.load(MODEL_PATH + \"MLP64.pt\", map_location = device)\n",
    "nmf_free = torch.load(MODEL_PATH + \"NeuMF64-free.pt\", map_location = device)\n",
    "nmf_init = torch.load(MODEL_PATH + \"scratch.pt\", map_location = device)\n",
    "\n",
    "nmf_freezed.to(device) \n",
    "gmf_best.to(device) \n",
    "mlp_best.to(device)\n",
    "nmf_free.to(device) \n",
    "nmf_init.to(device)\n",
    "\n",
    "HR, NDCG = {}, {}\n",
    "HR['NeuMF - freezed'], NDCG['NeuMF - freezed'] = metrics(nmf_freezed, test_loader, 10, device)\n",
    "HR['NeuMF - free'], NDCG['NeuMF - free'] = metrics(nmf_free, test_loader, 10, device)\n",
    "HR['NeuMF - init'], NDCG['NeuMF - init'] = metrics(nmf_init, test_loader, 10, device)\n",
    "HR['GMF'], NDCG['GMF'] = metrics(gmf_best, test_loader, 10, device)\n",
    "HR['MLP'], NDCG['MLP'] = metrics(mlp_best, test_loader, 10, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Best NDCG across models')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, layout = \"constrained\", figsize = (15, 5))\n",
    "for model, value in HR.items():\n",
    "    rect = ax[0].bar(model, value, width= 0.6)\n",
    "    ax[0].bar_label(rect, padding = 1)\n",
    "\n",
    "ax[0].set_ylabel(\"HR\")\n",
    "ax[0].set_ylim(0.5, 0.68)\n",
    "ax[0].set_title(\"Best Hit Rate across models\")\n",
    "\n",
    "for model, value in NDCG.items():\n",
    "    rect = ax[1].bar(model, value, width= 0.6)\n",
    "    ax[1].bar_label(rect, padding = 1)\n",
    "\n",
    "ax[1].set_ylabel(\"NDCG\")\n",
    "ax[1].set_ylim(0.3, 0.40)\n",
    "ax[1].set_title(\"Best NDCG across models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>181</td>\n",
       "      <td>1081</td>\n",
       "      <td>1</td>\n",
       "      <td>878962623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>276</td>\n",
       "      <td>796</td>\n",
       "      <td>1</td>\n",
       "      <td>874791932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>20</td>\n",
       "      <td>288</td>\n",
       "      <td>1</td>\n",
       "      <td>879667584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99926</th>\n",
       "      <td>868</td>\n",
       "      <td>405</td>\n",
       "      <td>1</td>\n",
       "      <td>877109082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99965</th>\n",
       "      <td>934</td>\n",
       "      <td>216</td>\n",
       "      <td>1</td>\n",
       "      <td>891191511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99970</th>\n",
       "      <td>449</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>879959573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99982</th>\n",
       "      <td>279</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>875308510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>874795795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6110 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating  timestamp\n",
       "2           22      377       1  878887116\n",
       "4          166      346       1  886397596\n",
       "36         181     1081       1  878962623\n",
       "38         276      796       1  874791932\n",
       "61          20      288       1  879667584\n",
       "...        ...      ...     ...        ...\n",
       "99926      868      405       1  877109082\n",
       "99965      934      216       1  891191511\n",
       "99970      449      120       1  879959573\n",
       "99982      279       64       1  875308510\n",
       "99997      276     1090       1  874795795\n",
       "\n",
       "[6110 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_100k = pd.read_csv(\n",
    "\tPATH, \n",
    "\tsep=\"\\t\", \n",
    "\tnames = ['user_id', 'item_id', 'rating', 'timestamp'], \n",
    "\tengine='python')\n",
    "\n",
    "# set the num_users, items\n",
    "num_users = ml_100k['user_id'].nunique()+1\n",
    "num_items = ml_100k['item_id'].nunique()+1\n",
    "\n",
    "# construct the train and test datasets\n",
    "#data = NCF_Data(ml_100k, args)\n",
    "#train_loader = data.get_train_instance()\n",
    "#test_loader = data.get_test_instance()\n",
    "ml_100k[ml_100k[\"rating\"] == 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
