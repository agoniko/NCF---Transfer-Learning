{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB CHALLENGE: Neural Matrix Factorization \n",
    "In the previous lecture we have built a recommender system using the Neural Matrix Factorization framework. This framework allowed us to combine the GMF layers with the MLP layers in this way:\n",
    "$$\\phi^{GMF} = \\mathbf{p_u}^G\\odot \\mathbf{q_i}^G$$\n",
    "$$\\phi^{MLP} = a_L(\\mathbf{W}_L^T(a_{L-1}(...a_2 (\\mathbf{W}_2^T \\begin{bmatrix}\n",
    "\\mathbf{p_u} \\\\ \\mathbf{q_i}\n",
    "\\end{bmatrix} + \\mathbf{b}_2)...)) + \\mathbf{b}_L)$$\n",
    "\n",
    "$$ y_{ui} = \\sigma(\\mathbf{h}^T \\begin{bmatrix}\n",
    "\\ \\phi^{GMF} \\\\ \\phi^{MLP}\n",
    "\\end{bmatrix})$$\n",
    "\n",
    "<center>  <img src=\"https://drive.google.com/uc?export=view&id=1gNLUpiQdbDPMdvfZYVs3lcou3cd4Favb\" width=\"550\" height=\"400\"> </center> \n",
    "\n",
    "Let's now try to apply transfer learning to such an architecture. \n",
    "\n",
    "- TASK 1: Train the GMF and MLP models separately, inspect and save the parameters.\n",
    "- TASK 2: Use the pre-trained parameters for initializing the NMF architecture. In particular, use the pre-trained embeddings for users and items and the initialized layers of GMF and MLP.\n",
    "- TASK 3: Finally, train the NMF model both by freezing the layers preceding the NeuMF layer and by keeping all the parameters trainable. Compare the performance with the network trained from scratch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from metrics import metrics\n",
    "from NCF_Data import NCF_Data\n",
    "from neumf import NeuMF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATH definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./ml-100k/u.data\" \n",
    "MODEL_PATH = \"./models/\" "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"seed\": 42,\n",
    "    \"lr\": 0.01,\n",
    "    \"dropout\": 0.2,\n",
    "    \"batch_size\": 256,\n",
    "    \"epochs\": 30,\n",
    "    \"top_k\": 10,\n",
    "    \"num_factors\": 32,\n",
    "    \"layers\": (64, 32, 16, 8),\n",
    "    \"out\": True,\n",
    "    \"num_ng\": 4,\n",
    "    \"num_ng_test\": 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = {\n",
    "    \"lr\": 0.01,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_factors_gmf\": 16,\n",
    "    \"num_factors_mlp\": 64,\n",
    "    \"epochs\": 30,\n",
    "    \"out\": True,\n",
    "    \"dropout\": (0, 0, 0, 0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(args[\"seed\"])\n",
    "torch.manual_seed(args[\"seed\"])\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train and Test loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "ml_100k = pd.read_csv(\n",
    "    DATA_PATH, sep=\"\\t\", names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    ")\n",
    "\n",
    "# set the num_users, items\n",
    "num_users = ml_100k[\"user_id\"].nunique() + 1\n",
    "num_items = ml_100k[\"item_id\"].nunique() + 1\n",
    "\n",
    "# construct the train and test datasets\n",
    "data = NCF_Data(ml_100k, args)\n",
    "train_loader = data.get_train_instance()\n",
    "test_loader = data.get_test_instance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>interacted_items</th>\n",
       "      <th>negative_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{273, 274, 275, 276, 277, 278, 279, 280, 281, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>{257, 258, 1, 10, 13, 14, 269, 272, 273, 274, ...</td>\n",
       "      <td>{2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>{258, 260, 264, 268, 271, 272, 288, 294, 299, ...</td>\n",
       "      <td>{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>{258, 260, 264, 11, 271, 288, 294, 300, 301, 3...</td>\n",
       "      <td>{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>{1, 2, 17, 21, 24, 25, 29, 40, 42, 50, 62, 63,...</td>\n",
       "      <td>{3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>939</td>\n",
       "      <td>{257, 258, 255, 1028, 9, 266, 15, 274, 275, 40...</td>\n",
       "      <td>{1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>940</td>\n",
       "      <td>{4, 516, 7, 8, 9, 521, 12, 14, 527, 529, 549, ...</td>\n",
       "      <td>{1, 2, 3, 5, 6, 10, 11, 13, 15, 16, 17, 18, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>941</td>\n",
       "      <td>{257, 258, 1, 7, 15, 273, 147, 919, 408, 294, ...</td>\n",
       "      <td>{2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>942</td>\n",
       "      <td>{514, 1028, 520, 528, 1050, 539, 31, 50, 71, 5...</td>\n",
       "      <td>{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>943</td>\n",
       "      <td>{2, 1028, 9, 11, 12, 526, 1044, 22, 23, 24, 10...</td>\n",
       "      <td>{1, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15, 16, 17, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id                                   interacted_items   \n",
       "0          1  {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  \\\n",
       "1          2  {257, 258, 1, 10, 13, 14, 269, 272, 273, 274, ...   \n",
       "2          3  {258, 260, 264, 268, 271, 272, 288, 294, 299, ...   \n",
       "3          4  {258, 260, 264, 11, 271, 288, 294, 300, 301, 3...   \n",
       "4          5  {1, 2, 17, 21, 24, 25, 29, 40, 42, 50, 62, 63,...   \n",
       "..       ...                                                ...   \n",
       "938      939  {257, 258, 255, 1028, 9, 266, 15, 274, 275, 40...   \n",
       "939      940  {4, 516, 7, 8, 9, 521, 12, 14, 527, 529, 549, ...   \n",
       "940      941  {257, 258, 1, 7, 15, 273, 147, 919, 408, 294, ...   \n",
       "941      942  {514, 1028, 520, 528, 1050, 539, 31, 50, 71, 5...   \n",
       "942      943  {2, 1028, 9, 11, 12, 526, 1044, 22, 23, 24, 10...   \n",
       "\n",
       "                                        negative_items  \n",
       "0    {273, 274, 275, 276, 277, 278, 279, 280, 281, ...  \n",
       "1    {2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 1...  \n",
       "2    {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  \n",
       "3    {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15...  \n",
       "4    {3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...  \n",
       "..                                                 ...  \n",
       "938  {1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 1...  \n",
       "939  {1, 2, 3, 5, 6, 10, 11, 13, 15, 16, 17, 18, 19...  \n",
       "940  {2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, ...  \n",
       "941  {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  \n",
       "942  {1, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15, 16, 17, ...  \n",
       "\n",
       "[943 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ml_100k = pd.read_csv(\n",
    "#     DATA_PATH, sep=\"\\t\", names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    "# )\n",
    "cp = ml_100k.copy(deep=True)\n",
    "cp[\"rating\"] = 1.0\n",
    "interact_status = (\n",
    "    cp.groupby(\"user_id\")[\"item_id\"]\n",
    "    .apply(set)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"item_id\": \"interacted_items\"})\n",
    ")\n",
    "interact_status['negative_items'] = interact_status['interacted_items'].apply(lambda x: set(cp[\"item_id\"]) - x)\n",
    "interact_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 431,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 461,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 560,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 600,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 608,\n",
       " 609,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 615,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 632,\n",
       " 633,\n",
       " 634,\n",
       " 635,\n",
       " 636,\n",
       " 637,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 644,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 661,\n",
       " 662,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 673,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 678,\n",
       " 679,\n",
       " 680,\n",
       " 681,\n",
       " 682,\n",
       " 683,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 687,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 697,\n",
       " 698,\n",
       " 699,\n",
       " 700,\n",
       " 701,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 715,\n",
       " 716,\n",
       " 717,\n",
       " 718,\n",
       " 719,\n",
       " 720,\n",
       " 721,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750,\n",
       " 751,\n",
       " 752,\n",
       " 753,\n",
       " 754,\n",
       " 755,\n",
       " 756,\n",
       " 757,\n",
       " 758,\n",
       " 759,\n",
       " 760,\n",
       " 761,\n",
       " 762,\n",
       " 763,\n",
       " 764,\n",
       " 765,\n",
       " 766,\n",
       " 767,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 779,\n",
       " 780,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 785,\n",
       " 786,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 790,\n",
       " 791,\n",
       " 792,\n",
       " 793,\n",
       " 794,\n",
       " 795,\n",
       " 796,\n",
       " 797,\n",
       " 798,\n",
       " 799,\n",
       " 800,\n",
       " 801,\n",
       " 802,\n",
       " 803,\n",
       " 804,\n",
       " 805,\n",
       " 806,\n",
       " 807,\n",
       " 808,\n",
       " 809,\n",
       " 810,\n",
       " 811,\n",
       " 812,\n",
       " 813,\n",
       " 814,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 818,\n",
       " 819,\n",
       " 820,\n",
       " 821,\n",
       " 822,\n",
       " 823,\n",
       " 824,\n",
       " 825,\n",
       " 826,\n",
       " 827,\n",
       " 828,\n",
       " 829,\n",
       " 830,\n",
       " 831,\n",
       " 832,\n",
       " 833,\n",
       " 834,\n",
       " 835,\n",
       " 836,\n",
       " 837,\n",
       " 838,\n",
       " 839,\n",
       " 840,\n",
       " 841,\n",
       " 842,\n",
       " 843,\n",
       " 844,\n",
       " 845,\n",
       " 846,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 850,\n",
       " 851,\n",
       " 852,\n",
       " 853,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 857,\n",
       " 858,\n",
       " 859,\n",
       " 860,\n",
       " 861,\n",
       " 862,\n",
       " 863,\n",
       " 864,\n",
       " 865,\n",
       " 866,\n",
       " 867,\n",
       " 868,\n",
       " 869,\n",
       " 870,\n",
       " 871,\n",
       " 872,\n",
       " 873,\n",
       " 874,\n",
       " 875,\n",
       " 876,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 880,\n",
       " 881,\n",
       " 882,\n",
       " 883,\n",
       " 884,\n",
       " 885,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 889,\n",
       " 890,\n",
       " 891,\n",
       " 892,\n",
       " 893,\n",
       " 894,\n",
       " 895,\n",
       " 896,\n",
       " 897,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 908,\n",
       " 909,\n",
       " 910,\n",
       " 911,\n",
       " 912,\n",
       " 913,\n",
       " 914,\n",
       " 915,\n",
       " 916,\n",
       " 917,\n",
       " 918,\n",
       " 919,\n",
       " 920,\n",
       " 921,\n",
       " 922,\n",
       " 923,\n",
       " 924,\n",
       " 925,\n",
       " 926,\n",
       " 927,\n",
       " 928,\n",
       " 929,\n",
       " 930,\n",
       " 931,\n",
       " 932,\n",
       " 933,\n",
       " 934,\n",
       " 935,\n",
       " 936,\n",
       " 937,\n",
       " 938,\n",
       " 939,\n",
       " 940,\n",
       " 941,\n",
       " 942,\n",
       " 943,\n",
       " 944,\n",
       " 945,\n",
       " 946,\n",
       " 947,\n",
       " 948,\n",
       " 949,\n",
       " 950,\n",
       " 951,\n",
       " 952,\n",
       " 953,\n",
       " 954,\n",
       " 955,\n",
       " 956,\n",
       " 957,\n",
       " 958,\n",
       " 959,\n",
       " 960,\n",
       " 961,\n",
       " 962,\n",
       " 963,\n",
       " 964,\n",
       " 965,\n",
       " 966,\n",
       " 967,\n",
       " 968,\n",
       " 969,\n",
       " 970,\n",
       " 971,\n",
       " 972,\n",
       " 973,\n",
       " 974,\n",
       " 975,\n",
       " 976,\n",
       " 977,\n",
       " 978,\n",
       " 979,\n",
       " 980,\n",
       " 981,\n",
       " 982,\n",
       " 983,\n",
       " 984,\n",
       " 985,\n",
       " 986,\n",
       " 987,\n",
       " 988,\n",
       " 989,\n",
       " 990,\n",
       " 991,\n",
       " 992,\n",
       " 993,\n",
       " 994,\n",
       " 995,\n",
       " 996,\n",
       " 997,\n",
       " 998,\n",
       " 999,\n",
       " 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(cp[\"item_id\"].unique())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module, train_loader: DataLoader, test_loader: DataLoader):\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args[\"lr\"])\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=args[\"lr\"])\n",
    "\n",
    "    best_hr = 0\n",
    "\n",
    "    # Train cycle\n",
    "    for epoch in range(args[\"epochs\"]):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train step\n",
    "        model.train()\n",
    "\n",
    "        for user, item, label in train_loader:\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            # Zero grad\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Prediction\n",
    "            prediction = model(user, item)\n",
    "            loss = loss_function(prediction, label)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Eval metrics\n",
    "        model.eval()\n",
    "        hr, ndcg = metrics(model, test_loader, args[\"top_k\"], device)\n",
    "\n",
    "        # Print metrics and time elapsed\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch:03d} time to train: {elapsed_time}\")\n",
    "        print(f\"HR: {np.mean(hr):.3f}\\tNDCG: {np.mean(ndcg):.3f}\")\n",
    "\n",
    "        # If best model, save it\n",
    "        if hr > best_hr:\n",
    "            best_hr = hr\n",
    "            if args[\"out\"]:\n",
    "                if not os.path.exists(MODEL_PATH):\n",
    "                    os.mkdir(MODEL_PATH)\n",
    "                torch.save(\n",
    "                    model,\n",
    "                    f\"{MODEL_PATH}{model.__class__.__name__}{model.num_factors}.pt\"\n",
    "                )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items):\n",
    "        super(GMF, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_factors = args[\"num_factors\"]\n",
    "\n",
    "        self.embedding_user = nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.num_factors\n",
    "        )\n",
    "        self.embedding_item = nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.num_factors\n",
    "        )\n",
    "\n",
    "        self.affine_output = nn.Linear(in_features=self.num_factors, out_features=1)\n",
    "        self.logistic = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding = self.embedding_user(user_indices)\n",
    "        item_embedding = self.embedding_item(item_indices)\n",
    "        element_product = torch.mul(user_embedding, item_embedding)\n",
    "        logits = self.affine_output(element_product)\n",
    "        rating = self.logistic(logits)\n",
    "        return rating.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gmf_model = GMF(num_users, num_items)\n",
    "#train_model(gmf_model, train_loader, test_loader)\n",
    "gmf_model = torch.load(MODEL_PATH + \"GMF8.pt\", map_location=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_users, num_items):\n",
    "        super(MLP, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_factors = args[\"num_factors\"]\n",
    "\n",
    "        self.embedding_user = nn.Embedding(\n",
    "            num_embeddings=num_users, embedding_dim=args[\"num_factors\"]\n",
    "        )\n",
    "        self.embedding_item = nn.Embedding(\n",
    "            num_embeddings=num_items, embedding_dim=args[\"num_factors\"]\n",
    "        )\n",
    "\n",
    "        layer_sizes = args[\"layers\"]\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(args[\"num_factors\"] * 2, layer_sizes[0]))\n",
    "        #layers.append(nn.ReLU())\n",
    "        for in_size, out_size in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            layers.append(nn.Linear(in_size, out_size))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.mlp_fc = nn.Sequential(*layers)\n",
    "        self.mlp_fc.add_module(\"affine\", nn.Linear(layer_sizes[-1], 1))\n",
    "        self.mlp_fc.add_module(\"logit\", nn.Sigmoid())\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding = self.embedding_user(user_indices)\n",
    "        item_embedding = self.embedding_item(item_indices)\n",
    "        vector = torch.cat([user_embedding, item_embedding], dim=-1)\n",
    "        rating = self.mlp_fc(vector)\n",
    "        return rating.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"args[\"lr\"] = 0.01\n",
    "args[\"dropout\"] = 0\n",
    "args[\"num_factors\"] = 64\n",
    "args['layers'] = [32, 16, 8]\n",
    "mlp_model = MLP(num_users, num_items)\n",
    "train_model(mlp_model, train_loader, test_loader)\"\"\"\n",
    "mlp_model = torch.load(MODEL_PATH + \"MLP64.pt\", map_location=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nmf_model = torch.load(MODEL_PATH + \"Assignment 1 - best.pt\", map_location=device)\n",
    "nmf_model = NeuMF(gmf_model.num_factors, mlp_model.num_factors, num_users, num_items)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining functions that load sub_models weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gmf_weights(nmf_model, gmf_model, requires_grad=False):\n",
    "    nmf_layers_names = [name for name, param in nmf_model.named_parameters()]\n",
    "    gmf_layers_names = [name for name, param in gmf_model.named_parameters()]\n",
    "    #create a dict that has as key the value of the layer in the NMF model and as value the layer in the GMF model\n",
    "    layers_name_match_dict = {k: v for k, v in zip(nmf_layers_names[:2], gmf_layers_names)}\n",
    "    for nmf_layer_name, gmf_layer_name in layers_name_match_dict.items():\n",
    "        nmf_model.state_dict()[nmf_layer_name].copy_(gmf_model.state_dict()[gmf_layer_name])\n",
    "    #deactivate grad for the layers that comes from the GMF model\n",
    "    for name, param in nmf_model.named_parameters():\n",
    "        if name in layers_name_match_dict.keys():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "\n",
    "def load_mlp_weights(nmf_model, mlp_model, requires_grad=False):\n",
    "    nmf_layers_names = [name for name, param in nmf_model.named_parameters()]\n",
    "    mlp_layers_names = [name for name, param in mlp_model.named_parameters()]\n",
    "    #create a dict that has as key the value of the layer in the NMF model and as value the layer in the MLP model\n",
    "    layers_name_match_dict = {k: v for k, v in zip(nmf_layers_names[4:], mlp_layers_names[:-2])}\n",
    "    for nmf_layer_name, mlp_layer_name in layers_name_match_dict.items():\n",
    "        nmf_model.state_dict()[nmf_layer_name].copy_(mlp_model.state_dict()[mlp_layer_name])\n",
    "    #deactivate grad for the layers that comes from the MLP model\n",
    "    for name, param in nmf_model.named_parameters():\n",
    "        if name in layers_name_match_dict.keys():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "\n",
    "def load_pre_trained_weights(nmf_model, gmf_model, mlp_model, requires_grad = False):\n",
    "    load_gmf_weights(nmf_model, gmf_model, requires_grad)\n",
    "    load_mlp_weights(nmf_model, mlp_model, requires_grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance with sum_models layers freezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NeuMF(gmf_model.num_factors, mlp_model.num_factors, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4653, -0.4930,  0.6697,  ..., -0.9396,  1.3414,  0.7344],\n",
       "        [-0.0364, -1.8768, -0.5430,  ...,  0.8550,  0.5962, -0.5022],\n",
       "        [ 0.8571, -0.4907,  0.1748,  ..., -2.0932, -1.8830,  0.3399],\n",
       "        ...,\n",
       "        [-0.9732, -1.2097,  0.1971,  ...,  0.0726, -0.9249,  0.1704],\n",
       "        [ 1.3458, -2.2545,  0.1308,  ..., -1.6214,  0.7462,  0.1759],\n",
       "        [-0.1957,  0.3733, -1.3767,  ...,  0.5236,  1.3268, -0.2997]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nmf_model.named_parameters())[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pre_trained_weights(nmf_model, gmf_model, mlp_model, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1514,  0.4690,  0.6961,  ...,  0.8707, -0.4645, -0.1457],\n",
       "        [ 0.2311,  0.8680, -0.6166,  ...,  1.5733, -0.4352,  0.3049],\n",
       "        [-0.1804,  1.0708,  0.9530,  ...,  0.9818,  1.4919,  0.7378],\n",
       "        ...,\n",
       "        [-2.6230,  0.1944, -0.3794,  ..., -0.5907, -0.1775, -0.0250],\n",
       "        [-0.3618,  1.9552,  0.1007,  ...,  0.6635, -0.0256, -1.0146],\n",
       "        [-0.4400,  2.0753, -0.6651,  ..., -0.6961,  0.1153,  1.3355]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nmf_model.named_parameters())[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmf_user_embed.0.weight False\n",
      "gmf_item_embed.0.weight False\n",
      "gmf_affine.weight True\n",
      "gmf_affine.bias True\n",
      "mlp_user_embed.0.weight False\n",
      "mlp_item_embed.0.weight False\n",
      "mlp_fc.0.weight False\n",
      "mlp_fc.0.bias False\n",
      "mlp_fc.3.weight False\n",
      "mlp_fc.3.bias False\n",
      "mlp_fc.6.weight False\n",
      "mlp_fc.6.bias False\n",
      "mlp_fc.9.weight False\n",
      "mlp_fc.9.bias False\n",
      "mixing_layers.0.weight True\n",
      "mixing_layers.0.bias True\n",
      "mixing_layers.3.weight True\n",
      "mixing_layers.3.bias True\n",
      "mixing_layers.6.weight True\n",
      "mixing_layers.6.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in nmf_model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args[\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 time to train: 40.60856246948242\n",
      "HR: 0.108\tNDCG: 0.045\n",
      "Epoch 001 time to train: 45.61992788314819\n",
      "HR: 0.102\tNDCG: 0.046\n",
      "Epoch 002 time to train: 37.16011095046997\n",
      "HR: 0.098\tNDCG: 0.041\n",
      "Epoch 003 time to train: 36.151079177856445\n",
      "HR: 0.089\tNDCG: 0.038\n",
      "Epoch 004 time to train: 36.515183448791504\n",
      "HR: 0.099\tNDCG: 0.045\n",
      "Epoch 005 time to train: 35.918678522109985\n",
      "HR: 0.104\tNDCG: 0.045\n",
      "Epoch 006 time to train: 40.13951563835144\n",
      "HR: 0.099\tNDCG: 0.044\n",
      "Epoch 007 time to train: 39.07959175109863\n",
      "HR: 0.102\tNDCG: 0.044\n",
      "Epoch 008 time to train: 35.99796986579895\n",
      "HR: 0.107\tNDCG: 0.047\n",
      "Epoch 009 time to train: 37.08579397201538\n",
      "HR: 0.097\tNDCG: 0.041\n",
      "Epoch 010 time to train: 34.22171425819397\n",
      "HR: 0.111\tNDCG: 0.048\n",
      "Epoch 011 time to train: 36.0052809715271\n",
      "HR: 0.104\tNDCG: 0.047\n",
      "Epoch 012 time to train: 34.38989281654358\n",
      "HR: 0.095\tNDCG: 0.043\n",
      "Epoch 013 time to train: 33.34105920791626\n",
      "HR: 0.100\tNDCG: 0.043\n",
      "Epoch 014 time to train: 33.93553686141968\n",
      "HR: 0.094\tNDCG: 0.043\n",
      "Epoch 015 time to train: 33.44881510734558\n",
      "HR: 0.105\tNDCG: 0.047\n",
      "Epoch 016 time to train: 33.99617552757263\n",
      "HR: 0.109\tNDCG: 0.048\n",
      "Epoch 017 time to train: 35.68755006790161\n",
      "HR: 0.098\tNDCG: 0.043\n",
      "Epoch 018 time to train: 35.96854043006897\n",
      "HR: 0.103\tNDCG: 0.048\n",
      "Epoch 019 time to train: 35.74416971206665\n",
      "HR: 0.097\tNDCG: 0.043\n",
      "Epoch 020 time to train: 35.99995946884155\n",
      "HR: 0.089\tNDCG: 0.041\n",
      "Epoch 021 time to train: 36.06906223297119\n",
      "HR: 0.105\tNDCG: 0.046\n",
      "Epoch 022 time to train: 35.97554802894592\n",
      "HR: 0.090\tNDCG: 0.041\n",
      "Epoch 023 time to train: 36.59109592437744\n",
      "HR: 0.094\tNDCG: 0.042\n",
      "Epoch 024 time to train: 36.12461066246033\n",
      "HR: 0.094\tNDCG: 0.042\n",
      "Epoch 025 time to train: 36.64852833747864\n",
      "HR: 0.099\tNDCG: 0.043\n",
      "Epoch 026 time to train: 36.103766679763794\n",
      "HR: 0.108\tNDCG: 0.048\n",
      "Epoch 027 time to train: 35.41432809829712\n",
      "HR: 0.101\tNDCG: 0.046\n",
      "Epoch 028 time to train: 36.53944134712219\n",
      "HR: 0.097\tNDCG: 0.043\n",
      "Epoch 029 time to train: 36.023242712020874\n",
      "HR: 0.102\tNDCG: 0.045\n"
     ]
    }
   ],
   "source": [
    "train_model(nmf_model, train_loader, test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance letting initialized layers free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmf_user_embed.0.weight True\n",
      "gmf_item_embed.0.weight True\n",
      "gmf_affine.weight True\n",
      "gmf_affine.bias True\n",
      "mlp_user_embed.0.weight True\n",
      "mlp_item_embed.0.weight True\n",
      "mlp_fc.0.weight True\n",
      "mlp_fc.0.bias True\n",
      "mlp_fc.3.weight True\n",
      "mlp_fc.3.bias True\n",
      "mlp_fc.6.weight True\n",
      "mlp_fc.6.bias True\n",
      "mlp_fc.9.weight True\n",
      "mlp_fc.9.bias True\n",
      "mixing_layers.0.weight True\n",
      "mixing_layers.0.bias True\n",
      "mixing_layers.3.weight True\n",
      "mixing_layers.3.bias True\n",
      "mixing_layers.6.weight True\n",
      "mixing_layers.6.bias True\n"
     ]
    }
   ],
   "source": [
    "nmf_model = NeuMF(gmf_model.num_factors, mlp_model.num_factors, num_users, num_items)\n",
    "load_pre_trained_weights(nmf_model, gmf_model, mlp_model, requires_grad=True)\n",
    "for name, param in nmf_model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 time to train: 40.07859539985657\n",
      "HR: 0.955\tNDCG: 0.955\n",
      "Epoch 001 time to train: 38.10337686538696\n",
      "HR: 0.988\tNDCG: 0.988\n",
      "Epoch 002 time to train: 38.809794664382935\n",
      "HR: 0.985\tNDCG: 0.985\n",
      "Epoch 003 time to train: 38.762298345565796\n",
      "HR: 0.992\tNDCG: 0.992\n",
      "Epoch 004 time to train: 39.592591285705566\n",
      "HR: 0.992\tNDCG: 0.992\n",
      "Epoch 005 time to train: 40.27716779708862\n",
      "HR: 0.989\tNDCG: 0.989\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_model(nmf_model, train_loader, test_loader)\n",
      "Cell \u001b[1;32mIn[24], line 32\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, test_loader)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[39m# Backpropagation\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> 32\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     34\u001b[0m \u001b[39m# Eval metrics\u001b[39;00m\n\u001b[0;32m     35\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\Eddie\\anaconda3\\envs\\neumf\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Eddie\\anaconda3\\envs\\neumf\\lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mc:\\Users\\Eddie\\anaconda3\\envs\\neumf\\lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[0;32m    133\u001b[0m         group,\n\u001b[0;32m    134\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    139\u001b[0m         state_steps)\n\u001b[1;32m--> 141\u001b[0m     adam(\n\u001b[0;32m    142\u001b[0m         params_with_grad,\n\u001b[0;32m    143\u001b[0m         grads,\n\u001b[0;32m    144\u001b[0m         exp_avgs,\n\u001b[0;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    147\u001b[0m         state_steps,\n\u001b[0;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\Eddie\\anaconda3\\envs\\neumf\\lib\\site-packages\\torch\\optim\\adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 281\u001b[0m func(params,\n\u001b[0;32m    282\u001b[0m      grads,\n\u001b[0;32m    283\u001b[0m      exp_avgs,\n\u001b[0;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    286\u001b[0m      state_steps,\n\u001b[0;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[0;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[0;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[0;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[1;32mc:\\Users\\Eddie\\anaconda3\\envs\\neumf\\lib\\site-packages\\torch\\optim\\adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    389\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    393\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(nmf_model, train_loader, test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_freezed = torch.load(MODEL_PATH + \"NeuMF64-freezed.pt\", map_location = device)\n",
    "gmf_best = torch.load(MODEL_PATH + \"GMF8.pt\", map_location = device)\n",
    "mlp_best = torch.load(MODEL_PATH + \"MLP64.pt\", map_location = device)\n",
    "nmf_free = torch.load(MODEL_PATH + \"NeuMF64-free.pt\", map_location = device)\n",
    "nmf_init = torch.load(MODEL_PATH + \"NeuMF64.pt\", map_location = device)\n",
    "\n",
    "nmf_freezed.to(device) \n",
    "gmf_best.to(device) \n",
    "mlp_best.to(device)\n",
    "nmf_free.to(device) \n",
    "nmf_init.to(device)\n",
    "\n",
    "hr, NDCG = {}, {}\n",
    "hr['NeuMF - freezed'], NDCG['NeuMF - freezed'] = metrics(nmf_freezed, test_loader, 10, device)\n",
    "hr['NeuMF - free'], NDCG['NeuMF - free'] = metrics(nmf_free, test_loader, 10, device)\n",
    "hr['NeuMF - init'], NDCG['NeuMF - init'] = metrics(nmf_init, test_loader, 10, device)\n",
    "hr['GMF'], NDCG['GMF'] = metrics(gmf_best, test_loader, 10, device)\n",
    "hr['MLP'], NDCG['MLP'] = metrics(mlp_best, test_loader, 10, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Best NDCG across models')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, layout = \"constrained\", figsize = (15, 5))\n",
    "for model, value in hr.items():\n",
    "    rect = ax[0].bar(model, value, width= 0.6)\n",
    "    ax[0].bar_label(rect, padding = 1)\n",
    "\n",
    "ax[0].set_ylabel(\"HR\")\n",
    "# ax[0].set_ylim(0.5, 0.68)\n",
    "ax[0].set_title(\"Best Hit Rate across models\")\n",
    "\n",
    "for model, value in NDCG.items():\n",
    "    rect = ax[1].bar(model, value, width= 0.6)\n",
    "    ax[1].bar_label(rect, padding = 1)\n",
    "\n",
    "ax[1].set_ylabel(\"NDCG\")\n",
    "# ax[1].set_ylim(0.3, 0.40)\n",
    "ax[1].set_title(\"Best NDCG across models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
