{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB CHALLENGE: Neural Matrix Factorization \n",
    "In the previous lecture we have built a recommender system using the Neural Matrix Factorization framework. This framework allowed us to combine the GMF layers with the MLP layers in this way:\n",
    "$$\\phi^{GMF} = \\mathbf{p_u}^G\\odot \\mathbf{q_i}^G$$\n",
    "$$\\phi^{MLP} = a_L(\\mathbf{W}_L^T(a_{L-1}(...a_2 (\\mathbf{W}_2^T \\begin{bmatrix}\n",
    "\\mathbf{p_u} \\\\ \\mathbf{q_i}\n",
    "\\end{bmatrix} + \\mathbf{b}_2)...)) + \\mathbf{b}_L)$$\n",
    "\n",
    "$$ y_{ui} = \\sigma(\\mathbf{h}^T \\begin{bmatrix}\n",
    "\\ \\phi^{GMF} \\\\ \\phi^{MLP}\n",
    "\\end{bmatrix})$$\n",
    "\n",
    "<center>  <img src=\"https://drive.google.com/uc?export=view&id=1gNLUpiQdbDPMdvfZYVs3lcou3cd4Favb\" width=\"550\" height=\"400\"> </center> \n",
    "\n",
    "Let's now try to apply transfer learning to such an architecture. \n",
    "\n",
    "- TASK 1: Train the GMF and MLP models separately, inspect and save the parameters.\n",
    "- TASK 2: Use the pre-trained parameters for initializing the NMF architecture. In particular, use the pre-trained embeddings for users and items and the initialized layers of GMF and MLP.\n",
    "- TASK 3: Finally, train the NMF model both by freezing the layers preceding the NeuMF layer and by keeping all the parameters trainable. Compare the performance with the network trained from scratch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from neumf import NeuMF\n",
    "from metrics import metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATH definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./ml-100k/u.data\" \n",
    "MODEL_PATH = \"./models/\" "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"seed\": 42,\n",
    "    \"lr\": 0.001,\n",
    "    \"dropout\": 0.2,\n",
    "    \"batch_size\": 256,\n",
    "    \"epochs\": 30,\n",
    "    \"top_k\": 10,\n",
    "    \"num_factors\": 32,\n",
    "    \"layers\": (32, 16, 8),\n",
    "    \"out\": True,\n",
    "    \"num_ng\": 4,\n",
    "    \"num_ng_test\": 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = {\n",
    "    \"lr\": 0.01,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_factors_gmf\": 16,\n",
    "    \"num_factors_mlp\": 64,\n",
    "    \"epochs\": 30,\n",
    "    \"out\": True,\n",
    "    \"dropout\": [0, 0, 0, 0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(args[\"seed\"])\n",
    "torch.manual_seed(args[\"seed\"])\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "ml_100k = pd.read_csv(\n",
    "\tPATH, \n",
    "\tsep=\"\\t\", \n",
    "\tnames = ['user_id', 'item_id', 'rating', 'timestamp'], \n",
    "\tengine='python')\n",
    "\n",
    "# set the num_users, items\n",
    "num_users = ml_100k['user_id'].nunique()+1\n",
    "num_items = ml_100k['item_id'].nunique()+1\n",
    "\n",
    "# construct the train and test datasets\n",
    "data = NCF_Data(ml_100k, args)\n",
    "train_loader = data.get_train_instance()\n",
    "test_loader = data.get_test_instance()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
