{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB CHALLENGE: Neural Matrix Factorization \n",
    "In the previous lecture we have built a recommender system using the Neural Matrix Factorization framework. This framework allowed us to combine the GMF layers with the MLP layers in this way:\n",
    "$$\\phi^{GMF} = \\mathbf{p_u}^G\\odot \\mathbf{q_i}^G$$\n",
    "$$\\phi^{MLP} = a_L(\\mathbf{W}_L^T(a_{L-1}(...a_2 (\\mathbf{W}_2^T \\begin{bmatrix}\n",
    "\\mathbf{p_u} \\\\ \\mathbf{q_i}\n",
    "\\end{bmatrix} + \\mathbf{b}_2)...)) + \\mathbf{b}_L)$$\n",
    "\n",
    "$$ y_{ui} = \\sigma(\\mathbf{h}^T \\begin{bmatrix}\n",
    "\\ \\phi^{GMF} \\\\ \\phi^{MLP}\n",
    "\\end{bmatrix})$$\n",
    "\n",
    "<center>  <img src=\"https://drive.google.com/uc?export=view&id=1gNLUpiQdbDPMdvfZYVs3lcou3cd4Favb\" width=\"550\" height=\"400\"> </center> \n",
    "\n",
    "Let's now try to apply transfer learning to such an architecture. \n",
    "\n",
    "- TASK 1: Train the GMF and MLP models separately, inspect and save the parameters.\n",
    "- TASK 2: Use the pre-trained parameters for initializing the NMF architecture. In particular, use the pre-trained embeddings for users and items and the initialized layers of GMF and MLP.\n",
    "- TASK 3: Finally, train the NMF model both by freezing the layers preceding the NeuMF layer and by keeping all the parameters trainable. Compare the performance with the network trained from scratch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "from metrics import metrics\n",
    "from NCF_Data import NCF_Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATH definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./ml-100k/u.data\" \n",
    "MODEL_PATH = \"./models/\" "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"seed\": 42,\n",
    "    \"lr\": 0.01,\n",
    "    \"dropout\": 0.2,\n",
    "    \"batch_size\": 256,\n",
    "    \"epochs\": 30,\n",
    "    \"top_k\": 10,\n",
    "    \"num_factors\": 32,\n",
    "    \"layers\": (64, 32, 16, 8),\n",
    "    \"out\": True,\n",
    "    \"num_ng\": 4,\n",
    "    \"num_ng_test\": 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = {\n",
    "    \"lr\": 0.01,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_factors_gmf\": 16,\n",
    "    \"num_factors_mlp\": 64,\n",
    "    \"epochs\": 30,\n",
    "    \"out\": True,\n",
    "    \"dropout\": (0, 0, 0, 0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(args[\"seed\"])\n",
    "torch.manual_seed(args[\"seed\"])\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train and Test loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "ml_100k = pd.read_csv(\n",
    "    DATA_PATH, sep=\"\\t\", names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    ")\n",
    "\n",
    "# set the num_users, items\n",
    "num_users = ml_100k[\"user_id\"].nunique() + 1\n",
    "num_items = ml_100k[\"item_id\"].nunique() + 1\n",
    "\n",
    "# construct the train and test datasets\n",
    "data = NCF_Data(ml_100k, args)\n",
    "train_loader = data.get_train_instance()\n",
    "test_loader = data.get_test_instance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>interacted_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>{257, 258, 1, 10, 13, 14, 269, 272, 273, 274, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>{258, 260, 264, 268, 271, 272, 288, 294, 299, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>{258, 260, 264, 11, 271, 288, 294, 300, 301, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>{1, 2, 17, 21, 24, 25, 29, 40, 42, 50, 62, 63,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>939</td>\n",
       "      <td>{257, 258, 255, 1028, 9, 266, 15, 274, 275, 40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>940</td>\n",
       "      <td>{4, 516, 7, 8, 9, 521, 12, 14, 527, 529, 549, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>941</td>\n",
       "      <td>{257, 258, 1, 7, 15, 273, 147, 919, 408, 294, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>942</td>\n",
       "      <td>{514, 1028, 520, 528, 1050, 539, 31, 50, 71, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>943</td>\n",
       "      <td>{2, 1028, 9, 11, 12, 526, 1044, 22, 23, 24, 10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id                                   interacted_items\n",
       "0          1  {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...\n",
       "1          2  {257, 258, 1, 10, 13, 14, 269, 272, 273, 274, ...\n",
       "2          3  {258, 260, 264, 268, 271, 272, 288, 294, 299, ...\n",
       "3          4  {258, 260, 264, 11, 271, 288, 294, 300, 301, 3...\n",
       "4          5  {1, 2, 17, 21, 24, 25, 29, 40, 42, 50, 62, 63,...\n",
       "..       ...                                                ...\n",
       "938      939  {257, 258, 255, 1028, 9, 266, 15, 274, 275, 40...\n",
       "939      940  {4, 516, 7, 8, 9, 521, 12, 14, 527, 529, 549, ...\n",
       "940      941  {257, 258, 1, 7, 15, 273, 147, 919, 408, 294, ...\n",
       "941      942  {514, 1028, 520, 528, 1050, 539, 31, 50, 71, 5...\n",
       "942      943  {2, 1028, 9, 11, 12, 526, 1044, 22, 23, 24, 10...\n",
       "\n",
       "[943 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ml_100k = pd.read_csv(\n",
    "#     DATA_PATH, sep=\"\\t\", names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    "# )\n",
    "cp = ml_100k.copy(deep=True)\n",
    "cp[\"rating\"] = 1.0\n",
    "interact_status = (\n",
    "    cp.groupby(\"user_id\")[\"item_id\"]\n",
    "    .apply(set)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"item_id\": \"interacted_items\"})\n",
    ")\n",
    "try:\n",
    "    interact_status[\"negative_items\"] = self.item_pool - interact_status[\"interacted_items\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module, train_loader: DataLoader, test_loader: DataLoader):\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    loss_function = nn.BCELoss()\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=args[\"lr\"])\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args[\"lr\"])\n",
    "\n",
    "    best_hr = 0\n",
    "\n",
    "    # Train cycle\n",
    "    for epoch in range(args[\"epochs\"]):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train step\n",
    "        model.train()\n",
    "\n",
    "        for user, item, label in train_loader:\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            # Zero grad\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Prediction\n",
    "            prediction = model(user, item)\n",
    "            loss = loss_function(prediction, label)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Eval metrics\n",
    "        model.eval()\n",
    "        hit_rates, ndcg = metrics(model, test_loader, args[\"top_k\"], device)\n",
    "\n",
    "        # Print metrics and time elapsed\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch:03d} time to train: {elapsed_time}\")\n",
    "        print(f\"HR: {np.mean(hit_rates):.3f}\\tNDCG: {np.mean(ndcg):.3f}\")\n",
    "\n",
    "        # If best model, save it\n",
    "        if hit_rates > best_hr:\n",
    "            best_hr, best_ndcg, best_epoch = hit_rates, ndcg, epoch\n",
    "            if args[\"out\"]:\n",
    "                if not os.path.exists(MODEL_PATH):\n",
    "                    os.mkdir(MODEL_PATH)\n",
    "                torch.save(\n",
    "                    model,\n",
    "                    f\"{MODEL_PATH}{model.__class__.__name__}{model.num_factors}.pt\"\n",
    "                )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items):\n",
    "        super(GMF, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_factors = args[\"num_factors\"]\n",
    "\n",
    "        self.embedding_user = nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.num_factors\n",
    "        )\n",
    "        self.embedding_item = nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.num_factors\n",
    "        )\n",
    "\n",
    "        self.affine_output = nn.Linear(in_features=self.num_factors, out_features=1)\n",
    "        self.logistic = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding = self.embedding_user(user_indices)\n",
    "        item_embedding = self.embedding_item(item_indices)\n",
    "        element_product = torch.mul(user_embedding, item_embedding)\n",
    "        logits = self.affine_output(element_product)\n",
    "        rating = self.logistic(logits)\n",
    "        return rating.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gmf_model = GMF(num_users, num_items)\n",
    "#train_model(gmf_model, train_loader, test_loader)\n",
    "gmf_model = torch.load(MODEL_PATH + \"GMF8.pt\", map_location=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_users, num_items):\n",
    "        super(MLP, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_factors = args[\"num_factors\"]\n",
    "\n",
    "        self.embedding_user = nn.Embedding(\n",
    "            num_embeddings=num_users, embedding_dim=args[\"num_factors\"]\n",
    "        )\n",
    "        self.embedding_item = nn.Embedding(\n",
    "            num_embeddings=num_items, embedding_dim=args[\"num_factors\"]\n",
    "        )\n",
    "\n",
    "        layer_sizes = args[\"layers\"]\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(args[\"num_factors\"] * 2, layer_sizes[0]))\n",
    "        #layers.append(nn.ReLU())\n",
    "        for in_size, out_size in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            layers.append(nn.Linear(in_size, out_size))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.mlp_fc = nn.Sequential(*layers)\n",
    "        self.mlp_fc.add_module(\"affine\", nn.Linear(layer_sizes[-1], 1))\n",
    "        self.mlp_fc.add_module(\"logit\", nn.Sigmoid())\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding = self.embedding_user(user_indices)\n",
    "        item_embedding = self.embedding_item(item_indices)\n",
    "        vector = torch.cat([user_embedding, item_embedding], dim=-1)\n",
    "        rating = self.mlp_fc(vector)\n",
    "        return rating.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"args[\"lr\"] = 0.01\n",
    "args[\"dropout\"] = 0\n",
    "args[\"num_factors\"] = 64\n",
    "args['layers'] = [32, 16, 8]\n",
    "mlp_model = MLP(num_users, num_items)\n",
    "train_model(mlp_model, train_loader, test_loader)\"\"\"\n",
    "mlp_model = torch.load(MODEL_PATH + \"MLP64.pt\", map_location=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nmf_model = torch.load(MODEL_PATH + \"Assignment 1 - best.pt\", map_location=device)\n",
    "nmf_model = NeuMF(gmf_model.num_factors, mlp_model.num_factors, num_users, num_items)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining functions that load sub_models weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gmf_weights(nmf_model, gmf_model, requires_grad=False):\n",
    "    nmf_layers_names = [name for name, param in nmf_model.named_parameters()]\n",
    "    gmf_layers_names = [name for name, param in gmf_model.named_parameters()]\n",
    "    #create a dict that has as key the value of the layer in the NMF model and as value the layer in the GMF model\n",
    "    layers_name_match_dict = {k: v for k, v in zip(nmf_layers_names[:2], gmf_layers_names)}\n",
    "    for nmf_layer_name, gmf_layer_name in layers_name_match_dict.items():\n",
    "        nmf_model.state_dict()[nmf_layer_name].copy_(gmf_model.state_dict()[gmf_layer_name])\n",
    "    #deactivate grad for the layers that comes from the GMF model\n",
    "    for name, param in nmf_model.named_parameters():\n",
    "        if name in layers_name_match_dict.keys():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "\n",
    "def load_mlp_weights(nmf_model, mlp_model, requires_grad=False):\n",
    "    nmf_layers_names = [name for name, param in nmf_model.named_parameters()]\n",
    "    mlp_layers_names = [name for name, param in mlp_model.named_parameters()]\n",
    "    #create a dict that has as key the value of the layer in the NMF model and as value the layer in the MLP model\n",
    "    layers_name_match_dict = {k: v for k, v in zip(nmf_layers_names[4:], mlp_layers_names[:-2])}\n",
    "    for nmf_layer_name, mlp_layer_name in layers_name_match_dict.items():\n",
    "        nmf_model.state_dict()[nmf_layer_name].copy_(mlp_model.state_dict()[mlp_layer_name])\n",
    "    #deactivate grad for the layers that comes from the MLP model\n",
    "    for name, param in nmf_model.named_parameters():\n",
    "        if name in layers_name_match_dict.keys():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "\n",
    "def load_pre_trained_weights(nmf_model, gmf_model, mlp_model, requires_grad = False):\n",
    "    load_gmf_weights(nmf_model, gmf_model, requires_grad)\n",
    "    load_mlp_weights(nmf_model, mlp_model, requires_grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance with sum_models layers freezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NeuMF(gmf_model.num_factors, mlp_model.num_factors, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nmf_model.named_parameters())[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pre_trained_weights(nmf_model, gmf_model, mlp_model, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nmf_model.named_parameters())[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in nmf_model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(nmf_model, train_loader, test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance letting initialized layers free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NeuMF(gmf_model.num_factors, mlp_model.num_factors, num_users, num_items)\n",
    "load_pre_trained_weights(nmf_model, gmf_model, mlp_model, requires_grad=True)\n",
    "for name, param in nmf_model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(nmf_model, train_loader, test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_freezed = torch.load(MODEL_PATH + \"NeuMF64-freezed.pt\", map_location = device)\n",
    "gmf_best = torch.load(MODEL_PATH + \"GMF8.pt\", map_location = device)\n",
    "mlp_best = torch.load(MODEL_PATH + \"MLP64.pt\", map_location = device)\n",
    "nmf_free = torch.load(MODEL_PATH + \"NeuMF64-free.pt\", map_location = device)\n",
    "nmf_init = torch.load(MODEL_PATH + \"Assignment 1 - best.pt\", map_location = device)\n",
    "\n",
    "nmf_freezed.to(device) \n",
    "gmf_best.to(device) \n",
    "mlp_best.to(device)\n",
    "nmf_free.to(device) \n",
    "nmf_init.to(device)\n",
    "\n",
    "hit_rates, NDCG = {}, {}\n",
    "hit_rates['NeuMF - freezed'], NDCG['NeuMF - freezed'] = metrics(nmf_freezed, test_loader, 10, device)\n",
    "hit_rates['NeuMF - free'], NDCG['NeuMF - free'] = metrics(nmf_free, test_loader, 10, device)\n",
    "hit_rates['NeuMF - init'], NDCG['NeuMF - init'] = metrics(nmf_init, test_loader, 10, device)\n",
    "hit_rates['GMF'], NDCG['GMF'] = metrics(gmf_best, test_loader, 10, device)\n",
    "hit_rates['MLP'], NDCG['MLP'] = metrics(mlp_best, test_loader, 10, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, layout = \"constrained\", figsize = (15, 5))\n",
    "for model, value in hit_rates.items():\n",
    "    rect = ax[0].bar(model, value, width= 0.6)\n",
    "    ax[0].bar_label(rect, padding = 1)\n",
    "\n",
    "ax[0].set_ylabel(\"HR\")\n",
    "ax[0].set_ylim(0.5, 0.68)\n",
    "ax[0].set_title(\"Best Hit Rate across models\")\n",
    "\n",
    "for model, value in NDCG.items():\n",
    "    rect = ax[1].bar(model, value, width= 0.6)\n",
    "    ax[1].bar_label(rect, padding = 1)\n",
    "\n",
    "ax[1].set_ylabel(\"NDCG\")\n",
    "ax[1].set_ylim(0.3, 0.40)\n",
    "ax[1].set_title(\"Best NDCG across models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
